{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Verbose = False\n",
    "if Verbose:\n",
    "    def vprint(*args, **kwargs): print(*args, **kwargs, flush=True)\n",
    "else: # do-nothing function\n",
    "    def vprint(*args, **kwargs): None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.width\", 380)\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./sick_train/SICK_train.txt\", sep=\"\\t\")\n",
    "df_train = df_train.drop(['relatedness_score'], axis=1)\n",
    "\n",
    "df_dev = pd.read_csv(\"./sick_trial/SICK_trial.txt\", sep=\"\\t\")\n",
    "df_dev = df_dev.drop(['relatedness_score'], axis=1)\n",
    "\n",
    "df_test = pd.read_csv(\"./sick_test/SICK_test.txt\", sep=\"\\t\")\n",
    "df_test = df_test.drop(['relatedness_score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SickDataset(Dataset):\n",
    "    endOfSentence   = '</s>'\n",
    "    startOfSentence = '<s>'\n",
    "    separator2Sentences = '<sep>'\n",
    "    \n",
    "    text_label = [\"NEUTRAL\", \"ENTAILMENT\", \"CONTRADICTION\"]\n",
    "    \n",
    "    tokens = [startOfSentence, separator2Sentences, endOfSentence]\n",
    "    \n",
    "    def join_sentence(self, row):\n",
    "        \"\"\"\n",
    "        Create a new sentence (<s> + s_A + <sep> + s_B + </s>)\n",
    "        \"\"\"\n",
    "        sentence_a = row['sentence_A'].lower().split(\" \")\n",
    "        sentence_b = row['sentence_B'].lower().split(\" \")\n",
    "        return np.concatenate((\n",
    "            [self.startOfSentence],\n",
    "            sentence_a,\n",
    "            [self.separator2Sentences],\n",
    "            sentence_b,\n",
    "            [self.endOfSentence]\n",
    "        ))\n",
    "    \n",
    "    def series_text_2_labelID(self, series, keep_n=1000):\n",
    "        \"\"\"\n",
    "        Convert text Label into label id\n",
    "        \"\"\"\n",
    "        reverse_dict = {v: k for k, v in  dict(enumerate(self.text_label)).items()}\n",
    "        return series.map(reverse_dict)\n",
    "    \n",
    "    def series_2_dict(self, series, keep_n):\n",
    "        \"\"\"\n",
    "        Convert document (a list of words) into a list of indexes\n",
    "        AND apply some filter on the documents\n",
    "        \"\"\"\n",
    "        dictionary = corpora.Dictionary(series)\n",
    "        dictionary.filter_extremes(\n",
    "            no_below=1,\n",
    "            no_above=1,\n",
    "            keep_n=keep_n,\n",
    "            keep_tokens=self.tokens)\n",
    "        return dictionary\n",
    "    \n",
    "    \n",
    "    def __init__(self, df, vocabulary_size, dic=None):\n",
    "        # Label text as ids\n",
    "        df[\"entailment_id\"] = self.series_text_2_labelID(df['entailment_judgment'])\n",
    "        \n",
    "        # Add <s>,</s>,<sep> tokens to the vocabulary\n",
    "        df['sentence_AB'] = df.apply(self.join_sentence, axis=1)\n",
    "        \n",
    "        # check if the dictionary is given\n",
    "        if dic is None:\n",
    "            # Create the Dictionary\n",
    "            self.dictionary = self.series_2_dict(df['sentence_AB'], vocabulary_size)\n",
    "        else:\n",
    "            self.dictionary = dic\n",
    "        \n",
    "        # sentence of words -> array of idx\n",
    "        # Adds unknown to the voc (idx = len(dictionary)), len(dictionary) = vocabulary_size\n",
    "        # Adds one to each (no tokens at 0, even <unk>)\n",
    "        # 0 is for the padding when using mini-batch\n",
    "        df[\"word_idx\"] = df[\"sentence_AB\"].apply(\n",
    "            lambda word: np.array(self.dictionary.doc2idx(word, unknown_word_index=vocabulary_size)) + 1\n",
    "        )\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "    def getRef(self, index):\n",
    "        return self.df['sentence_AB'][index]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            self.df['word_idx'][index],\n",
    "            self.df['entailment_id'][index])\n",
    "    \n",
    "    def getDictionary(self):\n",
    "        return self.dictionary\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "vocabulary_size = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>entailment_judgment</th>\n",
       "      <th>entailment_id</th>\n",
       "      <th>sentence_AB</th>\n",
       "      <th>word_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of kids is playing in a yard and an old man is standing in the background</td>\n",
       "      <td>A group of boys in a yard is playing and a man is standing in the background</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;s&gt;, a, group, of, kids, is, playing, in, a, yard, and, an, old, man, is, standing, in, the, ba...</td>\n",
       "      <td>[2, 4, 9, 14, 12, 11, 16, 10, 4, 19, 6, 5, 15, 13, 11, 17, 10, 18, 7, 3, 4, 9, 14, 8, 10, 4, 19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of children is playing in the house and there is no man standing in the background</td>\n",
       "      <td>A group of kids is playing in a yard and an old man is standing in the background</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;s&gt;, a, group, of, children, is, playing, in, the, house, and, there, is, no, man, standing, in...</td>\n",
       "      <td>[2, 4, 9, 14, 20, 11, 16, 10, 18, 21, 6, 23, 11, 22, 13, 17, 10, 18, 7, 3, 4, 9, 14, 12, 11, 16,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The young boys are playing outdoors and the man is smiling nearby</td>\n",
       "      <td>The kids are playing outdoors near a man with a smile</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;s&gt;, the, young, boys, are, playing, outdoors, and, the, man, is, smiling, nearby, &lt;sep&gt;, the, ...</td>\n",
       "      <td>[2, 18, 31, 8, 24, 16, 27, 6, 18, 13, 11, 29, 26, 3, 18, 12, 24, 16, 27, 25, 4, 13, 30, 4, 28, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are playing outdoors near a man with a smile</td>\n",
       "      <td>A group of kids is playing in a yard and an old man is standing in the background</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;s&gt;, the, kids, are, playing, outdoors, near, a, man, with, a, smile, &lt;sep&gt;, a, group, of, kids...</td>\n",
       "      <td>[2, 18, 12, 24, 16, 27, 25, 4, 13, 30, 4, 28, 3, 4, 9, 14, 12, 11, 16, 10, 4, 19, 6, 5, 15, 13, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The young boys are playing outdoors and the man is smiling nearby</td>\n",
       "      <td>A group of kids is playing in a yard and an old man is standing in the background</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;s&gt;, the, young, boys, are, playing, outdoors, and, the, man, is, smiling, nearby, &lt;sep&gt;, a, gr...</td>\n",
       "      <td>[2, 18, 31, 8, 24, 16, 27, 6, 18, 13, 11, 29, 26, 3, 4, 9, 14, 12, 11, 16, 10, 4, 19, 6, 5, 15, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_ID                                                                                  sentence_A                                                                         sentence_B entailment_judgment  entailment_id                                                                                          sentence_AB  \\\n",
       "0        1           A group of kids is playing in a yard and an old man is standing in the background       A group of boys in a yard is playing and a man is standing in the background             NEUTRAL              0  [<s>, a, group, of, kids, is, playing, in, a, yard, and, an, old, man, is, standing, in, the, ba...   \n",
       "1        2  A group of children is playing in the house and there is no man standing in the background  A group of kids is playing in a yard and an old man is standing in the background             NEUTRAL              0  [<s>, a, group, of, children, is, playing, in, the, house, and, there, is, no, man, standing, in...   \n",
       "2        3                           The young boys are playing outdoors and the man is smiling nearby                              The kids are playing outdoors near a man with a smile          ENTAILMENT              1  [<s>, the, young, boys, are, playing, outdoors, and, the, man, is, smiling, nearby, <sep>, the, ...   \n",
       "3        5                                       The kids are playing outdoors near a man with a smile  A group of kids is playing in a yard and an old man is standing in the background             NEUTRAL              0  [<s>, the, kids, are, playing, outdoors, near, a, man, with, a, smile, <sep>, a, group, of, kids...   \n",
       "4        9                           The young boys are playing outdoors and the man is smiling nearby  A group of kids is playing in a yard and an old man is standing in the background             NEUTRAL              0  [<s>, the, young, boys, are, playing, outdoors, and, the, man, is, smiling, nearby, <sep>, a, gr...   \n",
       "\n",
       "                                                                                              word_idx  \n",
       "0  [2, 4, 9, 14, 12, 11, 16, 10, 4, 19, 6, 5, 15, 13, 11, 17, 10, 18, 7, 3, 4, 9, 14, 8, 10, 4, 19,...  \n",
       "1  [2, 4, 9, 14, 20, 11, 16, 10, 18, 21, 6, 23, 11, 22, 13, 17, 10, 18, 7, 3, 4, 9, 14, 12, 11, 16,...  \n",
       "2    [2, 18, 31, 8, 24, 16, 27, 6, 18, 13, 11, 29, 26, 3, 18, 12, 24, 16, 27, 25, 4, 13, 30, 4, 28, 1]  \n",
       "3  [2, 18, 12, 24, 16, 27, 25, 4, 13, 30, 4, 28, 3, 4, 9, 14, 12, 11, 16, 10, 4, 19, 6, 5, 15, 13, ...  \n",
       "4  [2, 18, 31, 8, 24, 16, 27, 6, 18, 13, 11, 29, 26, 3, 4, 9, 14, 12, 11, 16, 10, 4, 19, 6, 5, 15, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the train dataset\n",
    "sick_dataset_train = SickDataset(df_train, vocabulary_size)\n",
    "sick_dataset_train.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dev dataset\n",
    "dictionary_train = sick_dataset_train.getDictionary()\n",
    "\n",
    "sick_dataset_dev = SickDataset(df_dev, vocabulary_size, dictionary_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the test dataset\n",
    "sick_dataset_test = SickDataset(df_test, vocabulary_size, dictionary_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>the</td>\n",
       "      <td>young</td>\n",
       "      <td>boys</td>\n",
       "      <td>are</td>\n",
       "      <td>playing</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>and</td>\n",
       "      <td>the</td>\n",
       "      <td>man</td>\n",
       "      <td>...</td>\n",
       "      <td>are</td>\n",
       "      <td>playing</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>near</td>\n",
       "      <td>a</td>\n",
       "      <td>man</td>\n",
       "      <td>with</td>\n",
       "      <td>a</td>\n",
       "      <td>smile</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1      2     3    4        5         6    7    8    9   ...    16       17        18    19 20   21    22 23     24    25\n",
       "0  <s>  the  young  boys  are  playing  outdoors  and  the  man  ...   are  playing  outdoors  near  a  man  with  a  smile  </s>\n",
       "1    2   18     31     8   24       16        27    6   18   13  ...    24       16        27    25  4   13    30  4     28     1\n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(sick_dataset_train.getRef(2), sick_dataset_train[2][0]))).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained embeddings\n",
    "https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76  \n",
    "For each word in dataset’s vocabulary, we check if it is on GloVe’s vocabulary. If it do it, we load its pre-trained word vector. Otherwise, we initialize a random vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: Pretained Embedding matrix: torch.Size([400000, 50])\n",
      "Adapted:    Pretained Embedding matrix: torch.Size([1502, 50])\n"
     ]
    }
   ],
   "source": [
    "from torchtext import vocab\n",
    "#vocab is shared across all the text fields\n",
    "#CAUTION: GloVe will download all embeddings locally (862 MB).\n",
    "pretrained_emb = vocab.GloVe(name='6B', dim=EMBEDDINGS_SIZE)\n",
    "\n",
    "# 0 is for the padding when using mini-batch (start at one, shift by one)\n",
    "weights_matrix = np.zeros((vocabulary_size + 2, EMBEDDINGS_SIZE)) # do not forget the unk\n",
    "\n",
    "# build a matrix of weights that will be loaded into the PyTorch embedding layer\n",
    "for word_id in sick_dataset_train.dictionary:\n",
    "    word = sick_dataset_train.dictionary[word_id]\n",
    "    if word in pretrained_emb.stoi:\n",
    "        pretrained_emb_ID = pretrained_emb.stoi[word]\n",
    "        \n",
    "        weights_matrix[word_id+1] = pretrained_emb.vectors[pretrained_emb_ID]\n",
    "    else:\n",
    "        weights_matrix[word_id+1] = np.random.normal(scale=0.6, size=(EMBEDDINGS_SIZE, ))\n",
    "        \n",
    "# UNK\n",
    "weights_matrix[vocabulary_size+1] = np.random.normal(scale=0.6, size=(EMBEDDINGS_SIZE, ))\n",
    "        \n",
    "pretrained_emb_vec = torch.tensor(weights_matrix, dtype=torch.float32)\n",
    "print(\"Downloaded: Pretained Embedding matrix: \" +  str(pretrained_emb.vectors.size()))\n",
    "print(\"Adapted:    Pretained Embedding matrix: \" +  str(pretrained_emb_vec.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, -1]\n",
      "the\n",
      "tensor([ 0.4180,  0.2497, -0.4124,  0.1217,  0.3453, -0.0445, -0.4969, -0.1786,\n",
      "        -0.0007, -0.6566,  0.2784, -0.1477, -0.5568,  0.1466, -0.0095,  0.0117,\n",
      "         0.1020, -0.1279, -0.8443, -0.1218, -0.0168, -0.3328, -0.1552, -0.2313,\n",
      "        -0.1918, -1.8823, -0.7675,  0.0991, -0.4212, -0.1953,  4.0071, -0.1859,\n",
      "        -0.5229, -0.3168,  0.0006,  0.0074,  0.1778, -0.1590,  0.0120, -0.0542,\n",
      "        -0.2987, -0.1575, -0.3476, -0.0456, -0.4425,  0.1878,  0.0028, -0.1841,\n",
      "        -0.1151, -0.7858])\n"
     ]
    }
   ],
   "source": [
    "print(sick_dataset_train.dictionary.doc2idx([\"the\", \"The\"]))\n",
    "print(sick_dataset_train.dictionary[17])\n",
    "print(pretrained_emb_vec[17+1])\n",
    "# Glove dim=50 word=the vector[:4] = 0.418 0.24968 -0.41242 0.1217"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    seqs_labels = np.array(batch)[:,1]\n",
    "    \n",
    "    vectorized_seqs = np.array(batch)[:,0]\n",
    "    seq_lengths = torch.LongTensor([len(x) for x in vectorized_seqs])\n",
    "    \n",
    "    seq_tensor = torch.zeros((len(vectorized_seqs), seq_lengths.max())).long()\n",
    "    for idx, (seq, seq_len) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "        \n",
    "    vectorized_seqs = np.array(seq_tensor)\n",
    "    \n",
    "    return torch.tensor(vectorized_seqs), torch.LongTensor([ x for x in seqs_labels])\n",
    "\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = DataLoader(dataset=sick_dataset_train,\n",
    "                          batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "dev_loader = DataLoader(dataset=sick_dataset_dev,\n",
    "                          batch_size=1, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=sick_dataset_test,\n",
    "                          batch_size=1, shuffle=False)\n",
    "\n",
    "# Debug the padding\n",
    "# display([ x for x in enumerate(train_loader)][0]) # has padding (sample of same size padded with 0)\n",
    "# display([ x for x in enumerate(dev_loader)][0]) # no batch == no padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import itertools\n",
    "\n",
    "def confusion_scores(total_labels, total_pred):\n",
    "    classes = SickDataset.text_label\n",
    "    title='Confusion matrix'\n",
    "    \n",
    "    cm = confusion_matrix(total_labels, total_pred, labels=[0, 1, 2])\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = [6, 5]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title, color='gray', fontsize=20)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, [c.lower() for c in classes], rotation=45 , style='italic', color='gray', fontsize=12)\n",
    "    plt.yticks(tick_marks, [c.lower() for c in classes], color='gray', style='italic', fontsize=12)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', color='gray', fontsize=14)\n",
    "    plt.xlabel('Predicted label', color='gray', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def evaluate(model, loader, whileTraining=False, criterion=None):\n",
    "    \"\"\"\n",
    "    Displays the confusion_matrix the precision recall fscore\n",
    "    If in whileTrainnig Mode only return the accuracy and loss\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_labels = []\n",
    "        total_pred = []\n",
    "        for _, (data, target) in enumerate(loader):\n",
    "\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                output = rnn(data)\n",
    "\n",
    "                # Get the Accuracy\n",
    "                _, predicted = torch.max(output.data, dim=1)\n",
    "                correct = (predicted == target).sum().item()\n",
    "                \n",
    "                total_labels.append(list(target.cpu().numpy()))\n",
    "                total_pred.append(list(predicted.cpu().numpy()))\n",
    "                \n",
    "        model.train()\n",
    "        if whileTraining and criterion!=None:\n",
    "            loss = criterion(output, target)\n",
    "            return ((accuracy_score(total_labels, total_pred) * 100), loss)\n",
    "\n",
    "                \n",
    "        confusion_scores(total_labels, total_pred)\n",
    "        \n",
    "        print(\"Accuracy:  {:.4f}\".format(accuracy_score(total_labels, total_pred)))\n",
    "        \n",
    "        # compute per-label precisions, recalls, F1-scores, and supports instead of averaging \n",
    "        metrics = precision_recall_fscore_support(\n",
    "                                        total_labels, total_pred,\n",
    "                                        average=None, labels=[0, 1, 2])\n",
    "        \n",
    "        df = pd.DataFrame(list(metrics), index=['Precision', 'Recall', 'Fscore', 'support'],\n",
    "                                   columns=SickDataset.text_label)\n",
    "        df = df.drop(['support'], axis=0)\n",
    "        display(df.T)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNClassifier(\n",
      "  (embedding): Embedding(1502, 50, padding_idx=0)\n",
      "  (rnn): GRU(50, 21, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=42, out_features=3, bias=True)\n",
      "  (softmax): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    # Our model\n",
    "\n",
    "    def __init__(self, input_voc_size, embedding_size, hidden_size):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        \n",
    "        self.input_voc_size = input_voc_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn_out_size = hidden_size * 2\n",
    "\n",
    "        \n",
    "        self.num_classes = 3\n",
    "        \n",
    "        # Add the padding token (0) (+1 to voc_size)\n",
    "        # Pads the output with the embedding vector at padding_idx whenever it encounters the index..\n",
    "        self.embedding = nn.Embedding(input_voc_size+1, embedding_size, padding_idx=0)\n",
    "        # Load the pretrained embeddings\n",
    "        #self.embedding.weight = nn.Parameter(pretrained_emb_vec) \n",
    "        # embeddings fine-tuning\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.rnn = nn.GRU(\n",
    "              input_size=embedding_size,\n",
    "              hidden_size=hidden_size,\n",
    "              batch_first=True,\n",
    "              bidirectional=True,\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.rnn_out_size, self.num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    # input shape: B x S (input size)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        vprint(\"\\nsize input\", x.size())\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Initialize hidden (num_layers * num_directions, batch_size, hidden_size)\n",
    "        h_0 = torch.zeros(2, batch_size, self.hidden_size)\n",
    "        vprint(\"size hidden init\", h_0.size())\n",
    "        \n",
    "        # When creating new variables inside a model (like the hidden state in an RNN/GRU/LSTM),\n",
    "        # make sure to also move them to the device (GPU or CPU).\n",
    "        h_0 = h_0.to(device)\n",
    "\n",
    "        # Embedding B x S -> B x S x I (embedding size)\n",
    "        emb = self.embedding(x)\n",
    "        vprint(\"size Embedding\", emb.size())\n",
    "        \n",
    "        # Propagate embedding through RNN\n",
    "        # Input: (batch, seq_len, embedding_size)\n",
    "        # h_0: (num_layers * num_directions, batch, hidden_size)\n",
    "        out, hidden = self.rnn(emb, h_0)\n",
    "        \n",
    "        vprint(\"size hidden\", hidden.size())\n",
    "        \n",
    "        rnn_out = torch.cat((hidden[0], hidden[1]), 1)\n",
    "        vprint(\"size rnn out\", rnn_out.size())\n",
    "        \n",
    "        \n",
    "        # Use the last layer output as FC's input\n",
    "        layout_fc1 = self.fc1(rnn_out)\n",
    "        vprint(\"size layout fc1\", layout_fc1.size())\n",
    "        \n",
    "        fc_output = self.softmax(layout_fc1)\n",
    "        \n",
    "        return fc_output    \n",
    "    \n",
    "# Add the unknown token (+1 to voc_size)\n",
    "rnn = RNNClassifier(vocabulary_size+1, EMBEDDINGS_SIZE, 21)\n",
    "rnn.to(device)\n",
    "print(rnn)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "weights = [1-((sick_dataset_train.df['entailment_id'] == i).sum() / len(sick_dataset_train)) for i in range(3)]\n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  1/35] | Step [ 2248/4500 (100%)] | Loss 1.112 | Accuracy 55.58% @ Loss_dev 0.741 | Accuracy_dev 61.20%\n",
      "Epoch [  2/35] | Step [ 2248/4500 (100%)] | Loss 0.952 | Accuracy 55.93% @ Loss_dev 0.861 | Accuracy_dev 61.60%\n",
      "Epoch [  3/35] | Step [ 2248/4500 (100%)] | Loss 0.881 | Accuracy 57.82% @ Loss_dev 0.779 | Accuracy_dev 62.20%\n",
      "Epoch [  4/35] | Step [ 2248/4500 (100%)] | Loss 0.773 | Accuracy 60.69% @ Loss_dev 1.061 | Accuracy_dev 56.20%\n",
      "Epoch [  5/35] | Step [ 2248/4500 (100%)] | Loss 0.699 | Accuracy 62.64% @ Loss_dev 0.833 | Accuracy_dev 58.00%\n",
      "Epoch [  6/35] | Step [ 2248/4500 (100%)] | Loss 0.558 | Accuracy 65.38% @ Loss_dev 0.787 | Accuracy_dev 60.80%\n",
      "Epoch [  7/35] | Step [ 2248/4500 (100%)] | Loss 0.567 | Accuracy 67.98% @ Loss_dev 0.608 | Accuracy_dev 62.20%\n",
      "Epoch [  8/35] | Step [ 2248/4500 (100%)] | Loss 0.606 | Accuracy 68.53%  @ Loss_dev 0.860 | Accuracy_dev 59.00%\n",
      "Epoch [  9/35] | Step [ 2248/4500 (100%)] | Loss 0.662 | Accuracy 70.36% @ Loss_dev 0.717 | Accuracy_dev 61.00%\n",
      "Epoch [ 10/35] | Step [ 2248/4500 (100%)] | Loss 0.810 | Accuracy 72.09% @ Loss_dev 0.621 | Accuracy_dev 60.60%\n",
      "Epoch [ 11/35] | Step [ 2248/4500 (100%)] | Loss 0.787 | Accuracy 72.64% @ Loss_dev 0.738 | Accuracy_dev 56.80%\n",
      "Epoch [ 12/35] | Step [ 2248/4500 (100%)] | Loss 0.646 | Accuracy 74.87% @ Loss_dev 0.571 | Accuracy_dev 58.80%\n",
      "Epoch [ 13/35] | Step [ 2248/4500 (100%)] | Loss 1.196 | Accuracy 75.96% @ Loss_dev 0.630 | Accuracy_dev 60.20%\n",
      "Epoch [ 14/35] | Step [ 2248/4500 (100%)] | Loss 0.796 | Accuracy 76.07% @ Loss_dev 0.559 | Accuracy_dev 60.40%\n",
      "Epoch [ 15/35] | Step [ 2248/4500 (100%)] | Loss 0.809 | Accuracy 77.56% @ Loss_dev 0.588 | Accuracy_dev 63.00%\n",
      "Epoch [ 16/35] | Step [ 2248/4500 (100%)] | Loss 0.696 | Accuracy 78.33% @ Loss_dev 0.697 | Accuracy_dev 60.00%\n",
      "Epoch [ 17/35] | Step [ 2248/4500 (100%)] | Loss 0.884 | Accuracy 78.47% @ Loss_dev 0.559 | Accuracy_dev 60.20%\n",
      "Epoch [ 18/35] | Step [ 2248/4500 (100%)] | Loss 0.560 | Accuracy 79.71% @ Loss_dev 0.574 | Accuracy_dev 60.40%\n",
      "Epoch [ 19/35] | Step [ 2248/4500 (100%)] | Loss 0.868 | Accuracy 79.38%  @ Loss_dev 1.174 | Accuracy_dev 60.60%\n",
      "Epoch [ 20/35] | Step [ 2248/4500 (100%)] | Loss 0.557 | Accuracy 80.38% @ Loss_dev 1.523 | Accuracy_dev 60.60%\n",
      "Epoch [ 21/35] | Step [ 2248/4500 (100%)] | Loss 0.932 | Accuracy 80.56% @ Loss_dev 1.446 | Accuracy_dev 58.80%\n",
      "Epoch [ 22/35] | Step [ 2248/4500 (100%)] | Loss 0.570 | Accuracy 80.96%  @ Loss_dev 0.594 | Accuracy_dev 59.20%\n",
      "Epoch [ 23/35] | Step [ 2248/4500 (100%)] | Loss 0.722 | Accuracy 81.53%  @ Loss_dev 0.552 | Accuracy_dev 61.20%\n",
      "Epoch [ 24/35] | Step [ 2248/4500 (100%)] | Loss 1.018 | Accuracy 81.98% @ Loss_dev 0.553 | Accuracy_dev 61.20%\n",
      "Epoch [ 25/35] | Step [ 2248/4500 (100%)] | Loss 0.802 | Accuracy 81.71% @ Loss_dev 1.548 | Accuracy_dev 60.00%\n",
      "Epoch [ 26/35] | Step [ 2248/4500 (100%)] | Loss 1.121 | Accuracy 81.29% @ Loss_dev 0.553 | Accuracy_dev 59.60%\n",
      "Epoch [ 27/35] | Step [ 2248/4500 (100%)] | Loss 0.767 | Accuracy 82.42% @ Loss_dev 0.902 | Accuracy_dev 62.00%\n",
      "Epoch [ 28/35] | Step [ 2248/4500 (100%)] | Loss 1.000 | Accuracy 82.58% @ Loss_dev 0.551 | Accuracy_dev 61.20%\n",
      "Epoch [ 29/35] | Step [ 2248/4500 (100%)] | Loss 0.565 | Accuracy 83.67%  @ Loss_dev 0.580 | Accuracy_dev 61.00%\n",
      "Epoch [ 30/35] | Step [ 2248/4500 (100%)] | Loss 1.031 | Accuracy 83.44% @ Loss_dev 1.105 | Accuracy_dev 60.40%\n",
      "Epoch [ 31/35] | Step [ 2248/4500 (100%)] | Loss 0.593 | Accuracy 83.76% @ Loss_dev 0.551 | Accuracy_dev 62.20%\n",
      "Epoch [ 32/35] | Step [ 2248/4500 (100%)] | Loss 0.568 | Accuracy 83.89%  @ Loss_dev 0.971 | Accuracy_dev 59.80%\n",
      "Epoch [ 33/35] | Step [ 2248/4500 (100%)] | Loss 0.552 | Accuracy 83.02%  @ Loss_dev 0.869 | Accuracy_dev 60.40%\n",
      "Epoch [ 34/35] | Step [ 2248/4500 (100%)] | Loss 0.635 | Accuracy 83.36% @ Loss_dev 0.551 | Accuracy_dev 62.40%\n",
      "Epoch [ 35/35] | Step [ 2248/4500 (100%)] | Loss 0.801 | Accuracy 83.36%  @ Loss_dev 0.551 | Accuracy_dev 61.40%\n",
      "Learning finished!\n",
      "CPU times: user 2min 45s, sys: 2.92 s, total: 2min 48s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train the model\n",
    "\n",
    "num_epochs=35\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "rnn.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_correct = 0\n",
    "    total_target = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        output = rnn(data)\n",
    "        \n",
    "        vprint(output)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        rnn.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Get the Accuracy\n",
    "        _, predicted = torch.max(output.data, dim=1)\n",
    "        correct = (predicted == target).sum().item()\n",
    "        \n",
    "        total_correct += correct\n",
    "        total_target += target.size(0)\n",
    "        \n",
    "        if batch_idx % 100 == 0 or batch_idx % 100 == 1 or batch_idx == len(train_loader)-1:\n",
    "            train_loss.append(loss.cpu().detach().numpy())\n",
    "            print('\\rEpoch [{:3}/{}] | Step [{:5}/{} ({:3.0f}%)] | Loss {:.3f} | Accuracy {:.2f}%'.format(\n",
    "                    epoch+1, num_epochs,\n",
    "                    batch_idx * len(data), \n",
    "                    len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), \n",
    "                    loss.item(), \n",
    "                    (total_correct / total_target) * 100), end=' ')\n",
    "            \n",
    "        if Verbose:\n",
    "            break\n",
    "            \n",
    "    accuracy_dev, loss_dev = evaluate(rnn, dev_loader, criterion=criterion, whileTraining=True)\n",
    "    print(\"@ Loss_dev {:.3f} | Accuracy_dev {:.2f}%\".format(loss_dev, accuracy_dev))\n",
    "\n",
    "\n",
    "print(\"Learning finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12e972709324996aec82a0b3dcb7b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='smooth', max=201, min=5, step=4), Output()), _dom_class…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "def update_losses(smooth=31):\n",
    "    plt.rcParams[\"figure.figsize\"] = [9, 7]\n",
    "    plt.title(\"Loss Curves\", color='gray', fontsize=20)\n",
    "    plt.xlabel('Steps', fontsize=16, color='gray')\n",
    "    plt.ylabel('Loss', fontsize=16, color='gray')\n",
    "    _line, = plt.plot(train_loss)\n",
    "    _line.set_ydata(savgol_filter(train_loss, smooth, 3))\n",
    "\n",
    "interact(update_losses, smooth=(5, 201, 4));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEUTRAL</th>\n",
       "      <td>0.680769</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>0.653137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTAILMENT</th>\n",
       "      <td>0.487013</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.503356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONTRADICTION</th>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Precision    Recall    Fscore\n",
       "NEUTRAL         0.680769  0.627660  0.653137\n",
       "ENTAILMENT      0.487013  0.520833  0.503356\n",
       "CONTRADICTION   0.639535  0.743243  0.687500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 196 ms, total: 1.38 s\n",
      "Wall time: 1.13 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "evaluate(rnn, dev_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.63 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# evaluate(rnn, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
